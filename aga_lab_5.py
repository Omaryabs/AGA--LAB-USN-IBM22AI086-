# -*- coding: utf-8 -*-
"""aga_lab_5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rjSi_f9twVGygD-_78fAW6rFRLzWkrEL
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.neural_network import BernoulliRBM
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
digits = load_digits()
X = digits.data
y = digits.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
def train_stacked_rbms(X_train, n_layers=3, n_components=64, n_iter=10):
    rbms = []
    current_input = X_train
    for layer in range(n_layers):
        rbm = BernoulliRBM(n_components=n_components, n_iter=n_iter, random_state=42)
        rbm.fit(current_input)
        rbms.append(rbm)
        current_input = rbm.transform(current_input)

    return rbms
def fine_tune_with_supervision(X_train, y_train, X_test, y_test, rbms, classifier=MLPClassifier()):

    current_input = X_train
    for rbm in rbms:
        current_input = rbm.transform(current_input)


    classifier.fit(current_input, y_train)

    current_input_test = X_test
    for rbm in rbms:
        current_input_test = rbm.transform(current_input_test)


    y_pred = classifier.predict(current_input_test)
    accuracy = classifier.score(current_input_test, y_test)


    print(f"Supervised Fine-Tuned Model Accuracy: {accuracy * 100:.2f}%")
    print(classification_report(y_test, y_pred))

    return classifier


def plot_rbms(rbms):
    for i, rbm in enumerate(rbms):
        #
        plt.figure(figsize=(8, 8))
        plt.suptitle(f"RBM Layer {i + 1}", size=16)
        for j in range(min(16, rbm.components_.shape[0])):
            plt.subplot(4, 4, j + 1)
            plt.imshow(rbm.components_[j].reshape(8, 8), cmap=plt.cm.gray)
            plt.axis('off')
        plt.show()


n_layers = 3
rbms = train_stacked_rbms(X_train, n_layers=n_layers, n_components=64, n_iter=10)


classifier = fine_tune_with_supervision(X_train, y_train, X_test, y_test, rbms)


plot_rbms(rbms)